{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esempi di regressione logistica nell'analisi del linguaggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis delle brevi recensioni"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad usare Python per allenare un modello di regressione logistica per eseguire un task di **sentiment analysis** analologo a quello che abbiamo usato come esmpio a lezione."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I dati"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo una piccola sezione del dataset contenuto nel corpus [Multiemo](https://clarin-pl.eu/dspace/handle/11321/798), un corpus multilingue contenente recensioni in 11 lingue in vari domini. Scegliamo i dati relativi al dominio *medico* in lingua italiana.\n",
    "\n",
    "Questo è un esempio del tipo di testi conenuti:\n",
    "\n",
    "\n",
    ">Super dottore e uomo da grande C . Grande esperienza e diagnosi accurate . Grande pazienza per gli anziani . Mi prendo cura della mia vecchia mamma da anni, e dico che siamo molto fortunati ad avere un medico del genere. Non so davvero cosa avremmo fatto se non fosse stato per il medico. Grazie a questo, mia madre è viva. Ogni visita ad uno specialista viene consultata con lui e penso che sia meglio di chiunque altro. Abbiamo una fiducia quasi illimitata in lui. Puoi fare molto di buono per il tuo medico ancora da scrivere. Purtroppo ha molti pazienti, è sovraccarico di lavoro (per questo temo anche per la sua salute) e l'accesso a lui è difficile ma sempre possibile. `__label__meta_plus_m`\n",
    "\n",
    "\n",
    "La classificazione è a 5 categorie: positivi, negativi, neutri, ambigui. Scartiamo tutti i testi classificati come ambigui e neutri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prima cosa che dobbiamo fare è trasformare i nostri testi in un vettore di *features* il cui impatto vogliamo misurare.\n",
    "\n",
    "Prendiamo spunto dalla discussione in [Jurafsky e Martin](https://web.stanford.edu/~jurafsky/slp3/) e usiamo queste 6 variabili:\n",
    "\n",
    "- nr. di parole positive\n",
    "- nr. di parole negative\n",
    "- contiene 'polarity shifters' (e.g. no, non, nessuno)? 1 se il testo ne contiene almeno una, altrimenti 0\n",
    "- conto di pronomi di 1a o 2a persona\n",
    "- punto esclamativo? 1 se il testo contiene il punto esclamativo; 0 in caso contrario\n",
    "- log del numero totale di parole"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per effettuare la classificazione in parole positive e negative (e anche per ottenere la lista dei *polarity shifters*) ho utilizzato un [lessico di polarità dell'italiano](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ILC-73) sviluppato dall'ILC-CNR.\n",
    "\n",
    "Questo è il codice che ho utilizzato per trasformare ogni testo in un vettore di feature:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def process_text(txt):\n",
    "    doc = nlp(txt)\n",
    "    positive_words = 0\n",
    "    negative_words = 0\n",
    "    hasShifters = 0\n",
    "    pronouns = 0\n",
    "    hasExclamations = 0\n",
    "    log_nr = math.log(len(doc))\n",
    "\n",
    "    for tok in doc:\n",
    "        pol = polarity_entries.get(tok.lemma_, 'null')\n",
    "        if pol == 'positive':\n",
    "            positive_words += 1\n",
    "        elif pol == 'negative':\n",
    "            negative_words += 1\n",
    "        \n",
    "        if tok.lemma_ in polarity_shifters:\n",
    "            hasShifters = 1\n",
    "\n",
    "        if tok.lemma_ in ['io', 'tu', 'noi', 'voi']:\n",
    "            pronouns += 1\n",
    "        \n",
    "        if tok.lower_ == '!':\n",
    "            hasExclamations = 1\n",
    "    return positive_words, negative_words, hasShifters, pronouns, hasExclamations, log_nr\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo caricare il dataset (il testo delle recensioni non è riprodotto per comodità)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/recensioni_feats.tsv', sep='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quante recensioni pos/neg ci sono?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alleniamo il modello"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo la libreria `sckitlearn` per creare ed allenare il modello. La funzione per addestrare il modello richiede due argomenti obbligatori:\n",
    "- una matrice che contiene la serie di features; immaginatela come una tabella con tante righe quante sono le nostre osservazioni e tante colonne quante sono le features\n",
    "- un vettore con le classificazioni corrette\n",
    "\n",
    "Cominciamo a creare l'input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PosWords', 'NegWords', 'hasShift', 'NrPron', 'hasExcl', 'logNr']].to_numpy()\n",
    "y = df.Label.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora creiamo il modello. \"Creare\" in questo caso non vuol dire *allenare* sui dati. Per ora, vuol solamente dire impostare il funzionamento generale del modello, settando alcuni parametri iniziali. La classe di modelli `LogisticRegression` di `sklearn` ha molti parametri iniziali che possono essere regolarati, come si può vedere dalla sua documentazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noi lavoriamo con i valori di default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo addestrare (\"fare il fit\") dei dati!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco fatto! Possiamo vedere quali sono i pesi e quale è l'intercetto calcolato dal modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo vedere le probabilità predette sui dati di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valutazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Riusiamo I dati di training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facile, no? Adesso, però, è necessario **valutare** il nostro modello, ovvero sapere quale capacità predittiva abbia il nostro modello! Come facciamo?\n",
    "\n",
    "Una risposta semplice semplice è quella di testare il nostro modello sugli stessi dati su cui si è addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uuuh... il nostro modello ha classificato correttamente solo il 67% dei testi di training... numeri non esattamente entusiasmanti!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo numero, peraltro non ci dice molto. Dove sbaglia il nostro classificatore? Quanti `positivi` classificati come `negativi` e viceversa abbiamo?\n",
    "\n",
    "Per avere questo dato possiamo usare una cosiddetta `matrice di confusione` (confusion matrix), ovvero una tabella di errori di predizioni che ci restituisca il numero di:\n",
    "- 0 classificati correttamente (veri negativi)\n",
    "- 0 classificati erroneamente (falsi negativi)\n",
    "- 1 classificati correttamente (veri positivi)\n",
    "- 1 classificati erroneamente (falsi positivi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, model.predict(X))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usare un test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il corpus Multiemo, però, suddivide i dati in 3 parti: train, dev, test. La cosa più corretta da fare è usare i dati di test per valutare le performance del nostro modello. I dati sono già stati organizzati in features e label. Carichiamoli e vediamo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/recensioni_feats_TEST.tsv', sep='\\t', index_col=0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['PosWords', 'NegWords', 'hasShift', 'NrPron', 'hasExcl', 'logNr']].to_numpy()\n",
    "y_test = df_test.Label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ancora la matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosa succederebbe se predicessimo sempre la classe più frequente (ovvero: positivo, 0)? Azzeccheremmo comunque un buon numero di previsioni. Otterremmo, cioè, una accuratezza del 58%. È questo il numero che ci dà una stima più realistica del miglioramento approtato dal nostro modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,  [0] * len(y_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui possiamo chiedere al modello di visualizzare le probabilità delle prime 10 osservazioni del test. Per ogni riga, il primo numero è la probabilità della classe 0, il secondo quella della classe 1.\n",
    "\n",
    "Ricordatevi che abbiamo posto la soglia a 0.5: la classe che supera la soglia è quella assegnata dal nostro classificatore. Ad es., nel primo caso 0 ha una probabilità uguale a 0.68; per il nostro classificatore il primo testo sarà positivo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui possiamo chiedere di darci in output le label che corrispondono alla probabilità:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O addirittura possiamo stampare `positivo` e `negativo` come etichetta corrispondente a 0 e 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in model.predict(X_test)[:10]:\n",
    "    if res == 0:\n",
    "        print(\"positivo\")\n",
    "    else:\n",
    "        print(\"negativo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Che cos'è il **bias** $b$ che osserviamo nella proprietà del modello `model.intercept_` e che compare nella formula:\n",
    "\n",
    "$z = \\vec{w} \\cdot \\vec{x} + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricordiamo che $b$, in questa formula, equivale a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se avessimo un testo $x$ rappresentato da un vettore contenente solo una sequenza di 0 (ovvero: se tutte le feature del nostro testo fossero uguali a 0) otterremmo queste probabilità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba([[0] * 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ricordate che le probabilità (meglio, la probabilità $p$ della classe 1, dato che la probabilità della classe 0 è semplicemente 1-p) sono calcolate applicando la funzione logistica a $z$.\n",
    "\n",
    "Dunque, che risultato otterremo se applicassimo una funzione ci permette di passare dalla probabilità della classe 1 quando tutte le features sono 0 al nostro coefficiente $z$?\n",
    "\n",
    "La funzione che ci permette di passare dalle probabilità ai log-odds ($z$) è la cosidetta funzione *logit*:\n",
    "\n",
    "$z = \\log \\left(\\frac{p}{1-p}\\right)$\n",
    "\n",
    "Questo è il codice python che serve a calcolarla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logit(x):\n",
    "    # le prima 2 righe di codice sono un buon modo per assicurarci che il valore passato \n",
    "    # sia una probabilità valida (tra 0 e 1)\n",
    "    if x <= 0 or x >= 1:\n",
    "        raise ValueError(\"Probability must be between 0 and 1, exclusive.\")\n",
    "    \n",
    "    return math.log(x / (1 - x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamola con la probabilità della classe 1 quando tutti i valori delle feature sono 0 (ovvero $p=0.97116054$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit(0.97116054)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nostro bias è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il bias non è nient'altro che il valore di $z$ quando il prodotto tra le feature ($\\vec{x}$) e i pesi ($\\vec{w}$) risulta 0\n",
    "\n",
    "*CVD*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un aspetto utile della regressione logistica è che possiamo usare i pesi ($\\vec{w}$) per farci un'idea delle variabili che influiscono di più sulla classificazione: l'idea (molto grossolana) è che più alto è il peso, più alta sarà l'influenza della feature in questione.\n",
    "\n",
    "Possiamo (informalmente) utilizzare [queste formule](https://sefiks.com/2021/01/06/feature-importance-in-logistic-regression/) per avere un'idea dell'importanza relativa delle diverse features all'interno dell'equazione del modello. Ma una lettura attenta di un buon manuale di statistica per linguisti, come quello di [Gries](https://www.degruyter.com/document/doi/10.1515/9783110718256/html) citato più sotto. è fondamentale per chi volesse utilizzare i modelli lineari più seriamente per lo studio linguistico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(['PosWords', 'NegWords', 'hasShift', 'NrPron', 'hasExcl', 'logNr'], columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e, model.coef_[0])\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=False)\n",
    "ax = feature_importance.plot.barh(x='feature', y='importance')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studio Linguistico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il libro *Statistics for Linguistics with R: A Practical Introduction* ([vedi qui](https://www.degruyter.com/document/doi/10.1515/9783110718256/html)) di S. Gries contiene una dettagliata e splendida spiegazione dell'uso della regressione logistica (insieme ad altri modelli) per lo studio linguistico.\n",
    "\n",
    "Tra i vari dataset di esempio, ce n'è uno molto interessante (usato da Gries per illustrare la regressione logistica in contesto di studio quantitativo) relativo al posizionamento delle subordinate temporali e causali rispetto alla principale in un corpus misto inglese e tedesco. È riprodotto qui (dalla seconda ed. che io possiedo) nel file `data/clauseorder.csv`. \n",
    "\n",
    "Carichiamolo e diamogli un'occhiata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clauseorders.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quello che noi vogliamo predire è l'ordine delle proposizioni, che qui è registrato nella colonna `ORDER`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ORDER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['SUBORDTYPE', 'LEN_MC', 'LEN_SC', 'LENGTH_DIFF',\n",
    "       'CONJ', 'MORETHAN2CL']\n",
    "to_factorize = ['SUBORDTYPE', 'CONJ', 'MORETHAN2CL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in to_factorize:\n",
    "    df[col] = df[col].factorize()[0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui *non* ripeteremo le analisi molto sofisticate che Gries discute nel suo libro. Ci limitiamo a giocare un po' con un modello creato con `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformiamo le due categorie in 0 e 1: sc-mc diventa 0\n",
    "y = df.ORDER.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', penalty='none', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[feats].values\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo (informalmente) utilizzare [queste formule](https://sefiks.com/2021/01/06/feature-importance-in-logistic-regression/) per avere un'idea dell'importanza relativa delle diverse features all'interno dell'equazione del modello. Ma una lettura attenta di Gries è fondamentale per chi volesse utilizzare i modelli lineari più seriamente per lo studio linguistico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(feats, columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e, model.coef_[0])\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=False)\n",
    "ax = feature_importance.plot.barh(x='feature', y='importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
