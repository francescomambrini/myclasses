{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esempi di regressione logistica nell'analisi del linguaggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis delle brevi recensioni"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo ad usare Python per allenare un modello di regressione logistica per eseguire un task di **sentiment analysis** analologo a quello che abbiamo usato come esmpio a lezione."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I dati"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo una piccola sezione del dataset contenuto nel corpus [Multiemo](https://clarin-pl.eu/dspace/handle/11321/798), un corpus multilingue contenente recensioni in 11 lingue in vari domini. Scegliamo i dati relativi al dominio *medico* in lingua italiana.\n",
    "\n",
    "Questo è un esempio del tipo di testi conenuti:\n",
    "\n",
    "\n",
    ">Super dottore e uomo da grande C . Grande esperienza e diagnosi accurate . Grande pazienza per gli anziani . Mi prendo cura della mia vecchia mamma da anni, e dico che siamo molto fortunati ad avere un medico del genere. Non so davvero cosa avremmo fatto se non fosse stato per il medico. Grazie a questo, mia madre è viva. Ogni visita ad uno specialista viene consultata con lui e penso che sia meglio di chiunque altro. Abbiamo una fiducia quasi illimitata in lui. Puoi fare molto di buono per il tuo medico ancora da scrivere. Purtroppo ha molti pazienti, è sovraccarico di lavoro (per questo temo anche per la sua salute) e l'accesso a lui è difficile ma sempre possibile. `__label__meta_plus_m`\n",
    "\n",
    "\n",
    "La classificazione è a 5 categorie: positivi, negativi, neutri, ambigui. Scartiamo tutti i testi classificati come ambigui e neutri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La prima cosa che dobbiamo fare è trasformare i nostri testi in un vettore di *features* il cui impatto vogliamo misurare.\n",
    "\n",
    "Prendiamo spunto dalla discussione in [Jurafsky e Martin](https://web.stanford.edu/~jurafsky/slp3/) e usiamo queste 6 variabili:\n",
    "\n",
    "- nr. di parole positive\n",
    "- nr. di parole negative\n",
    "- contiene 'polarity shifters' (e.g. no, non, nessuno)? 1 se il testo ne contiene almeno una, altrimenti 0\n",
    "- conto di pronomi di 1a o 2a persona\n",
    "- punto esclamativo? 1 se il testo contiene il punto esclamativo; 0 in caso contrario\n",
    "- log del numero totale di parole"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per effettuare la classificazione in parole positive e negative (e anche per ottenere la lista dei *polarity shifters*) ho utilizzato un [lessico di polarità dell'italiano](https://dspace-clarin-it.ilc.cnr.it/repository/xmlui/handle/20.500.11752/ILC-73) sviluppato dall'ILC-CNR.\n",
    "\n",
    "Questo è il codice che ho utilizzato per trasformare ogni testo in un vettore di feature:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def process_text(txt):\n",
    "    doc = nlp(txt)\n",
    "    positive_words = 0\n",
    "    negative_words = 0\n",
    "    hasShifters = 0\n",
    "    pronouns = 0\n",
    "    hasExclamations = 0\n",
    "    log_nr = math.log(len(doc))\n",
    "\n",
    "    for tok in doc:\n",
    "        pol = polarity_entries.get(tok.lemma_, 'null')\n",
    "        if pol == 'positive':\n",
    "            positive_words += 1\n",
    "        elif pol == 'negative':\n",
    "            negative_words += 1\n",
    "        \n",
    "        if tok.lemma_ in polarity_shifters:\n",
    "            hasShifters = 1\n",
    "\n",
    "        if tok.lemma_ in ['io', 'tu', 'noi', 'voi']:\n",
    "            pronouns += 1\n",
    "        \n",
    "        if tok.lower_ == '!':\n",
    "            hasExclamations = 1\n",
    "    return positive_words, negative_words, hasShifters, pronouns, hasExclamations, log_nr\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo caricare il dataset (il testo delle recensioni non è riprodotto per comodità)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PosWords</th>\n",
       "      <th>NegWords</th>\n",
       "      <th>hasShift</th>\n",
       "      <th>NrPron</th>\n",
       "      <th>hasExcl</th>\n",
       "      <th>logNr</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LineNr.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.905275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.941642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.779123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.497168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PosWords  NegWords  hasShift  NrPron  hasExcl     logNr  Label\n",
       "LineNr.                                                                \n",
       "1              13         2         1       0        0  4.905275      1\n",
       "2               8         2         1       0        0  4.941642      0\n",
       "3              10         5         0       0        0  4.779123      1\n",
       "4              13         3         1       0        0  4.553877      1\n",
       "5              12         4         1       0        1  5.497168      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/recensioni_feats.tsv', sep='\\t', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quante recensioni pos/neg ci sono?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    957\n",
       "1    764\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alleniamo il modello"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo la libreria `sckitlearn` per creare ed allenare il modello. La funzione per addestrare il modello richiede due argomenti obbligatori:\n",
    "- una matrice che contiene la serie di features; immaginatela come una tabella con tante righe quante sono le nostre osservazioni e tante colonne quante sono le features\n",
    "- un vettore con le classificazioni corrette\n",
    "\n",
    "Cominciamo a creare l'input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PosWords', 'NegWords', 'hasShift', 'NrPron', 'hasExcl', 'logNr']].to_numpy()\n",
    "y = df.Label.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora creiamo il modello. \"Creare\" in questo caso non vuol dire *allenare* sui dati. Per ora, vuol solamente dire impostare il funzionamento generale del modello, settando alcuni parametri iniziali. La classe di modelli `LogisticRegression` di `sklearn` ha molti parametri iniziali che possono essere regolarati, come si può vedere dalla sua documentazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      " |  that regularization is applied by default**. It can handle both dense\n",
      " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      " |  floats for optimal performance; any other input format will be converted\n",
      " |  (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      " |  'saga' solver.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
      " |      Specify the norm of the penalty:\n",
      " |  \n",
      " |      - `'none'`: no penalty is added;\n",
      " |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      " |      - `'l1'`: add a L1 penalty term;\n",
      " |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         Some penalties may not work with some solvers. See the parameter\n",
      " |         `solver` below, to know the compatibility between the penalty and\n",
      " |         solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default=False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      " |      data. See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      " |      To choose a solver, you might want to consider the following aspects:\n",
      " |  \n",
      " |          - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      " |            and 'saga' are faster for large ones;\n",
      " |          - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      " |            'lbfgs' handle multinomial loss;\n",
      " |          - 'liblinear' is limited to one-versus-rest schemes.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         The choice of the algorithm depends on the penalty chosen:\n",
      " |         Supported penalties by solver:\n",
      " |  \n",
      " |         - 'newton-cg'   -   ['l2', 'none']\n",
      " |         - 'lbfgs'       -   ['l2', 'none']\n",
      " |         - 'liblinear'   -   ['l1', 'l2']\n",
      " |         - 'sag'         -   ['l2', 'none']\n",
      " |         - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
      " |  \n",
      " |      .. note::\n",
      " |         'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |         features with approximately the same scale. You can\n",
      " |         preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
      " |  \n",
      " |      .. seealso::\n",
      " |         Refer to the User Guide for more information regarding\n",
      " |         :class:`LogisticRegression` and more specifically the\n",
      " |         `Table <https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression>`_\n",
      " |         summarazing solver/penalty supports.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default=100\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  l1_ratio : float, default=None\n",
      " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |          :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
      " |          for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :])\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,) default=None\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is proportional to the signed\n",
      " |      distance of that sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the confidence scores.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      " |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      " |          this class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the predictions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Vector containing the class labels for each sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noi lavoriamo con i valori di default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo addestrare (\"fare il fit\") dei dati!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco fatto! Possiamo vedere quali sono i pesi e quale è l'intercetto calcolato dal modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.51674717])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08800761, -0.16689316, -1.32284647, -0.03628668,  0.31080057,\n",
       "        -0.60220009]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo vedere le probabilità predette sui dati di training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48743856, 0.51256144],\n",
       "       [0.60149119, 0.39850881],\n",
       "       [0.33528692, 0.66471308],\n",
       "       [0.47627408, 0.52372592],\n",
       "       [0.60280713, 0.39719287],\n",
       "       [0.51425592, 0.48574408],\n",
       "       [0.6244055 , 0.3755945 ],\n",
       "       [0.32758341, 0.67241659],\n",
       "       [0.75234066, 0.24765934],\n",
       "       [0.84127996, 0.15872004]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valutazione"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Riusiamo I dati di training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facile, no? Adesso, però, è necessario **valutare** il nostro modello, ovvero sapere quale capacità predittiva abbia il nostro modello! Come facciamo?\n",
    "\n",
    "Una risposta semplice semplice è quella di testare il nostro modello sugli stessi dati su cui si è addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6717024985473562"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uuuh... il nostro modello ha classificato correttamente solo il 67% dei testi di training... numeri non esattamente entusiasmanti!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo numero, peraltro non ci dice molto. Dove sbaglia il nostro classificatore? Quanti `positivi` classificati come `negativi` e viceversa abbiamo?\n",
    "\n",
    "Per avere questo dato possiamo usare una cosiddetta `matrice di confusione` (confusion matrix), ovvero una tabella di errori di predizioni che ci restituisca il numero di:\n",
    "- 0 classificati correttamente (veri negativi)\n",
    "- 0 classificati erroneamente (falsi negativi)\n",
    "- 1 classificati correttamente (veri positivi)\n",
    "- 1 classificati erroneamente (falsi positivi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[788, 169],\n",
       "       [396, 368]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y, model.predict(X))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.82      0.74       957\n",
      "           1       0.69      0.48      0.57       764\n",
      "\n",
      "    accuracy                           0.67      1721\n",
      "   macro avg       0.68      0.65      0.65      1721\n",
      "weighted avg       0.67      0.67      0.66      1721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, model.predict(X)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usare un test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il corpus Multiemo, però, suddivide i dati in 3 parti: train, dev, test. La cosa più corretta da fare è usare i dati di test per valutare le performance del nostro modello. I dati sono già stati organizzati in features e label. Carichiamoli e vediamo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PosWords</th>\n",
       "      <th>NegWords</th>\n",
       "      <th>hasShift</th>\n",
       "      <th>NrPron</th>\n",
       "      <th>hasExcl</th>\n",
       "      <th>logNr</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LineNr.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.532599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.859812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.814131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.951244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.099866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PosWords  NegWords  hasShift  NrPron  hasExcl     logNr  Label\n",
       "LineNr.                                                                \n",
       "1               5         4         1       0        0  4.532599      0\n",
       "2               8         3         1       0        0  4.859812      0\n",
       "3              35        14         1       0        0  5.814131      0\n",
       "4               1         0         0       0        0  3.951244      1\n",
       "5              16         7         1       0        0  5.099866      1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/recensioni_feats_TEST.tsv', sep='\\t', index_col=0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test[['PosWords', 'NegWords', 'hasShift', 'NrPron', 'hasExcl', 'logNr']].to_numpy()\n",
    "y_test = df_test.Label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.77       133\n",
      "           1       0.72      0.47      0.57        97\n",
      "\n",
      "    accuracy                           0.70       230\n",
      "   macro avg       0.71      0.67      0.67       230\n",
      "weighted avg       0.70      0.70      0.69       230\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo ancora la matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73       133\n",
      "           1       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           0.58       230\n",
      "   macro avg       0.29      0.50      0.37       230\n",
      "weighted avg       0.33      0.58      0.42       230\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/data/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/data/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/data/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,  [0] * len(y_test) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68204065, 0.31795935],\n",
       "       [0.62931923, 0.37068077],\n",
       "       [0.63728677, 0.36271323],\n",
       "       [0.22700238, 0.77299762],\n",
       "       [0.65415864, 0.34584136],\n",
       "       [0.63292361, 0.36707639],\n",
       "       [0.48275403, 0.51724597],\n",
       "       [0.51694238, 0.48305762],\n",
       "       [0.49653384, 0.50346616],\n",
       "       [0.72552642, 0.27447358]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02883946, 0.97116054]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba([[0] * 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.51674717])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def ilogit(x):\n",
    "    il = 1 / (1 + math.exp(x))\n",
    "    return il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028839460870607812"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilogit(3.51674717)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studio Linguistico"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il libro *Statistics for Linguistics with R: A Practical Introduction* [vedi qui](https://www.degruyter.com/document/doi/10.1515/9783110718256/html) di S. Gries contiene una dettagliata e splendida spiegazione dell'uso della regressione logistica (insieme ad altri modelli) per lo studio linguistico.\n",
    "\n",
    "Tra i vari dataset di esempio, ce n'è uno molto interessante (usato da Gries per illustrare la regressione logistica in contesto di studio quantitativo) relativo al posizionamento delle subordinate temporali e causali rispetto alla principale in un corpus misto inglese e tedesco. È riprodotto qui (dalla seconda ed. che io possiedo) nel file `data/clauseorder.csv`. \n",
    "\n",
    "Carichiamolo e diamogli un'occhiata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE</th>\n",
       "      <th>ORDER</th>\n",
       "      <th>SUBORDTYPE</th>\n",
       "      <th>LEN_MC</th>\n",
       "      <th>LEN_SC</th>\n",
       "      <th>LENGTH_DIFF</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>MORETHAN2CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4777</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>temp</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>-6</td>\n",
       "      <td>als/when</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1698</td>\n",
       "      <td>mc-sc</td>\n",
       "      <td>temp</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>als/when</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>953</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>temp</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>als/when</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681</td>\n",
       "      <td>mc-sc</td>\n",
       "      <td>temp</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>-9</td>\n",
       "      <td>als/when</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4055</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>temp</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>als/when</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CASE  ORDER SUBORDTYPE  LEN_MC  LEN_SC  LENGTH_DIFF      CONJ MORETHAN2CL\n",
       "0  4777  sc-mc       temp       4      10           -6  als/when          no\n",
       "1  1698  mc-sc       temp       7       6            1  als/when          no\n",
       "2   953  sc-mc       temp      12       7            5  als/when         yes\n",
       "3  1681  mc-sc       temp       6      15           -9  als/when          no\n",
       "4  4055  sc-mc       temp       9       5            4  als/when         yes"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clauseorders.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quello che noi vogliamo predire è l'ordine delle proposizioni, che qui è registrato nella colonna `ORDER`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mc-sc    275\n",
       "sc-mc    128\n",
       "Name: ORDER, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ORDER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['SUBORDTYPE', 'LEN_MC', 'LEN_SC', 'LENGTH_DIFF',\n",
    "       'CONJ', 'MORETHAN2CL']\n",
    "to_factorize = ['SUBORDTYPE', 'CONJ', 'MORETHAN2CL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE</th>\n",
       "      <th>ORDER</th>\n",
       "      <th>SUBORDTYPE</th>\n",
       "      <th>LEN_MC</th>\n",
       "      <th>LEN_SC</th>\n",
       "      <th>LENGTH_DIFF</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>MORETHAN2CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4777</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1698</td>\n",
       "      <td>mc-sc</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>953</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681</td>\n",
       "      <td>mc-sc</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4055</td>\n",
       "      <td>sc-mc</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CASE  ORDER  SUBORDTYPE  LEN_MC  LEN_SC  LENGTH_DIFF  CONJ  MORETHAN2CL\n",
       "0  4777  sc-mc           0       4      10           -6     0            0\n",
       "1  1698  mc-sc           0       7       6            1     0            0\n",
       "2   953  sc-mc           0      12       7            5     0            1\n",
       "3  1681  mc-sc           0       6      15           -9     0            0\n",
       "4  4055  sc-mc           0       9       5            4     0            1"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in to_factorize:\n",
    "    df[col] = df[col].factorize()[0]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui *non* ripeteremo le analisi molto sofisticate che Gries discute nel suo libro. Ci limitiamo a giocare un po' con un modello creato con `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformiamo le due categorie in 0 e 1: sc-mc diventa 0\n",
    "y = df.ORDER.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', penalty='none', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;none&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;none&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='none', random_state=0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[feats].values\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7667493796526055"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.62135434, -0.01808965,  0.00706139, -0.02515104,  0.06792462,\n",
       "        -0.76710495]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo (informalmente) utilizzare [queste formule](https://sefiks.com/2021/01/06/feature-importance-in-logistic-regression/) per avere un'idea dell'importanza relativa delle diverse features all'interno dell'equazione del modello. Ma una lettura attenta di Gries è fondamentale per chi volesse utilizzare i modelli lineari più seriamente per lo studio linguistico!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame(feats, columns = [\"feature\"])\n",
    "feature_importance[\"importance\"] = pow(math.e, model.coef_[0])\n",
    "feature_importance = feature_importance.sort_values(by = [\"importance\"], ascending=False)\n",
    "ax = feature_importance.plot.barh(x='feature', y='importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUBORDTYPE</td>\n",
       "      <td>13.754339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONJ</td>\n",
       "      <td>1.070285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LEN_SC</td>\n",
       "      <td>1.007086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LEN_MC</td>\n",
       "      <td>0.982073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LENGTH_DIFF</td>\n",
       "      <td>0.975163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MORETHAN2CL</td>\n",
       "      <td>0.464355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "0   SUBORDTYPE   13.754339\n",
       "4         CONJ    1.070285\n",
       "2       LEN_SC    1.007086\n",
       "1       LEN_MC    0.982073\n",
       "3  LENGTH_DIFF    0.975163\n",
       "5  MORETHAN2CL    0.464355"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-env",
   "language": "python",
   "name": "data-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
