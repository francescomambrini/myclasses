{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
    "import regex\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's decide which corpus we'd like to work with (pick the name of the folder!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = 'ChiLit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set!\n"
     ]
    }
   ],
   "source": [
    "r = os.path.join('data', corpus_name)\n",
    "\n",
    "# next lines check that the directory is good; it raise an exception if not\n",
    "# otherwhise, 'All set!' will be printed\n",
    "assert os.path.isdir(r), f'You did not specify a valid path ({r} does not exist)'\n",
    "print('All set!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = PlaintextCorpusReader(r, r'.*\\.txt')\n",
    "len(corpus.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = stopwords.words('english')\n",
    "stops[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tok):\n",
    "    return regex.sub(r'[^\\p{L}]+', '', tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = corpus.fileids()\n",
    "\n",
    "docs = []\n",
    "for f in files:\n",
    "    words = [clean(w.lower()) for w in corpus.words(f) if w.lower() not in stops]\n",
    "    docs.append(' '.join([w for w in words if w != '']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TD-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build 2 dataframes:\n",
    "* `raw_df`: raw frequencies obtained with sklearn's vectorizer\n",
    "* `idf_df`: the tf-idf normalized dataframe created following Jurafsky \n",
    "\n",
    "In the Appendix, we will add a third:\n",
    "* `dt_df`: tf-idf normalized frequencies using `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we define a couple of functions to get the top-n words and texts from the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pass a dataframe, a text and a number n; returns the top-n words attested in the text\n",
    "def get_top_from_df(df, text, n=20):\n",
    "    return df.loc[text].sort_values(ascending=False).head(n)\n",
    "\n",
    "# We pass a dataframe, a word and a number n; returns the top-n texts where the word is most attested\n",
    "def get_top_text_word(df, word, n=20):\n",
    "    return df[word].sort_values(ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-Term Matrix with raw frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaarh</th>\n",
       "      <th>aah</th>\n",
       "      <th>aall</th>\n",
       "      <th>aamash</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abana</th>\n",
       "      <th>...</th>\n",
       "      <th>zéphyrine</th>\n",
       "      <th>zōōt</th>\n",
       "      <th>zōōts</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æons</th>\n",
       "      <th>æschylus</th>\n",
       "      <th>æsthetic</th>\n",
       "      <th>æsthetical</th>\n",
       "      <th>éperon</th>\n",
       "      <th>ôsso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amulet.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brass.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa  aaarh  aah  aall  aamash  aaron  ab  aback  abaft  abana  \\\n",
       "alice.txt     0      0    0     0       0      0   0      0      0      0   \n",
       "alone.txt     0      0    0     0       0      0   0      0      0      0   \n",
       "amulet.txt    0      0    0     0       0      0   0      0      0      0   \n",
       "beauty.txt    0      0    0     0       0      0   0      0      0      0   \n",
       "brass.txt     0      0    0     0       8      0   0      0      0      0   \n",
       "\n",
       "            ...  zéphyrine  zōōt  zōōts  æneas  æons  æschylus  æsthetic  \\\n",
       "alice.txt   ...          0     0      0      0     0         0         0   \n",
       "alone.txt   ...          0     0      0      0     0         0         0   \n",
       "amulet.txt  ...          0     0      0      0     0         0         0   \n",
       "beauty.txt  ...          0     0      0      0     0         0         0   \n",
       "brass.txt   ...          0     0      0      0     0         0         0   \n",
       "\n",
       "            æsthetical  éperon  ôsso  \n",
       "alice.txt            0       0     0  \n",
       "alone.txt            0       0     0  \n",
       "amulet.txt           0       0     0  \n",
       "beauty.txt           0       0     0  \n",
       "brass.txt            0       0     0  \n",
       "\n",
       "[5 rows x 43936 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the CountVectorizer object without normalization (default is normalization='l2')\n",
    "raw_vectorizer = CountVectorizer(analyzer='word',\n",
    "                                #  max_df=.9,\n",
    "                                #  min_df=2, \n",
    "                                 lowercase=False, \n",
    "                                 stop_words=None, \n",
    "                                 binary=False,\n",
    "                                 )\n",
    "\n",
    "# Fit and transform the documents\n",
    "dtm = raw_vectorizer.fit_transform(docs)\n",
    "\n",
    "# Convert the DTM to a dense array for easier manipulation\n",
    "dtm_array = dtm.toarray()\n",
    "\n",
    "# Get the feature (word) names\n",
    "feature_names = raw_vectorizer.get_feature_names_out()\n",
    "\n",
    "raw_df = pd.DataFrame(dtm_array, columns=feature_names, index=files)\n",
    "\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alice.txt          3\n",
       "alone.txt         53\n",
       "amulet.txt        20\n",
       "beauty.txt        78\n",
       "brass.txt         10\n",
       "                ... \n",
       "water.txt         36\n",
       "willows.txt        4\n",
       "wind.txt         119\n",
       "winning.txt       17\n",
       "woodmagic.txt      6\n",
       "Name: boy, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['boy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the top-5 documents with the highest number of attestations for the target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eric.txt        288\n",
       "dominics.txt    286\n",
       "tombrown.txt    215\n",
       "vice.txt        209\n",
       "daisy.txt       207\n",
       "Name: boy, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_text_word(raw_df, 'boy', n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And these are the top-20 most frequent words in R.L. Stevenson's *Treasure Island*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "said       323\n",
       "one        278\n",
       "man        260\n",
       "captain    234\n",
       "silver     222\n",
       "like       207\n",
       "could      174\n",
       "doctor     172\n",
       "would      169\n",
       "us         166\n",
       "well       156\n",
       "upon       152\n",
       "see        142\n",
       "time       131\n",
       "good       129\n",
       "hand       122\n",
       "still      120\n",
       "old        119\n",
       "ship       116\n",
       "long       115\n",
       "Name: treasure.txt, dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_from_df(raw_df, 'treasure.txt', n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF, IDF, Tf-Idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to calculate idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(col):\n",
    "    docf = col[col != 0].count()\n",
    "    idf = log10(len(col) / docf)\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we create a vector of all idf's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = raw_df.apply(get_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we scale all term freq's with log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_raw_df = raw_df.replace(0, 1)\n",
    "tf_norms = np.log10(norm_raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf_norms` now holds all term freq scaled with log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaarh</th>\n",
       "      <th>aah</th>\n",
       "      <th>aall</th>\n",
       "      <th>aamash</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abana</th>\n",
       "      <th>...</th>\n",
       "      <th>zéphyrine</th>\n",
       "      <th>zōōt</th>\n",
       "      <th>zōōts</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æons</th>\n",
       "      <th>æschylus</th>\n",
       "      <th>æsthetic</th>\n",
       "      <th>æsthetical</th>\n",
       "      <th>éperon</th>\n",
       "      <th>ôsso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amulet.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brass.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.90309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa  aaarh  aah  aall   aamash  aaron   ab  aback  abaft  abana  \\\n",
       "alice.txt   0.0    0.0  0.0   0.0  0.00000    0.0  0.0    0.0    0.0    0.0   \n",
       "alone.txt   0.0    0.0  0.0   0.0  0.00000    0.0  0.0    0.0    0.0    0.0   \n",
       "amulet.txt  0.0    0.0  0.0   0.0  0.00000    0.0  0.0    0.0    0.0    0.0   \n",
       "beauty.txt  0.0    0.0  0.0   0.0  0.00000    0.0  0.0    0.0    0.0    0.0   \n",
       "brass.txt   0.0    0.0  0.0   0.0  0.90309    0.0  0.0    0.0    0.0    0.0   \n",
       "\n",
       "            ...  zéphyrine  zōōt  zōōts  æneas  æons  æschylus  æsthetic  \\\n",
       "alice.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "alone.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "amulet.txt  ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "beauty.txt  ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "brass.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "\n",
       "            æsthetical  éperon  ôsso  \n",
       "alice.txt          0.0     0.0   0.0  \n",
       "alone.txt          0.0     0.0   0.0  \n",
       "amulet.txt         0.0     0.0   0.0  \n",
       "beauty.txt         0.0     0.0   0.0  \n",
       "brass.txt          0.0     0.0   0.0  \n",
       "\n",
       "[5 rows x 43936 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf_norms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df.abandon['brass.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we multiply the scaled df x the idf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaarh</th>\n",
       "      <th>aah</th>\n",
       "      <th>aall</th>\n",
       "      <th>aamash</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abana</th>\n",
       "      <th>...</th>\n",
       "      <th>zéphyrine</th>\n",
       "      <th>zōōt</th>\n",
       "      <th>zōōts</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æons</th>\n",
       "      <th>æschylus</th>\n",
       "      <th>æsthetic</th>\n",
       "      <th>æsthetical</th>\n",
       "      <th>éperon</th>\n",
       "      <th>ôsso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amulet.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brass.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.671853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43936 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa  aaarh  aah  aall    aamash  aaron   ab  aback  abaft  abana  \\\n",
       "alice.txt   0.0    0.0  0.0   0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "alone.txt   0.0    0.0  0.0   0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "amulet.txt  0.0    0.0  0.0   0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "beauty.txt  0.0    0.0  0.0   0.0  0.000000    0.0  0.0    0.0    0.0    0.0   \n",
       "brass.txt   0.0    0.0  0.0   0.0  1.671853    0.0  0.0    0.0    0.0    0.0   \n",
       "\n",
       "            ...  zéphyrine  zōōt  zōōts  æneas  æons  æschylus  æsthetic  \\\n",
       "alice.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "alone.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "amulet.txt  ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "beauty.txt  ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "brass.txt   ...        0.0   0.0    0.0    0.0   0.0       0.0       0.0   \n",
       "\n",
       "            æsthetical  éperon  ôsso  \n",
       "alice.txt          0.0     0.0   0.0  \n",
       "alone.txt          0.0     0.0   0.0  \n",
       "amulet.txt         0.0     0.0   0.0  \n",
       "beauty.txt         0.0     0.0   0.0  \n",
       "brass.txt          0.0     0.0   0.0  \n",
       "\n",
       "[5 rows x 43936 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_df = tf_norms * idfs\n",
    "idf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abandon in `brass.txt` should be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2625256421919799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log10(3) * log10((71 / 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2625256421919799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_df.abandon['brass.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captain in `treasure.txt` should be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42446987578531514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log10(234) * log10((71 / 47))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42446987578531514"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idf_df.captain['treasure.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoo in `amulet.txt` should be..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896654615984174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0.896655\n",
    "log10(raw_df.zoo['amulet.txt']) * log10((71 / 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the idf list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one       0.000000\n",
       "back      0.000000\n",
       "head      0.000000\n",
       "came      0.000000\n",
       "went      0.000000\n",
       "            ...   \n",
       "tell      0.025184\n",
       "used      0.025184\n",
       "many      0.025184\n",
       "night     0.025184\n",
       "things    0.025184\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs.sort_values(ascending=True).head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us define a function to get the ranking in the idf list of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(word, series):\n",
    "    sorted_series = series.sort_values(ascending=True)\n",
    "    ranked_series = sorted_series.rank()\n",
    "    return ranked_series.loc[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rank('wild', idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter using DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may be interested to filter out words that are:\n",
    "* too frequent: they occur in all, or nearly all documents (\"said\", \"went\", \"boy\"...)\n",
    "* too specific: they occur only in text (mostly, specific proper nouns, like Irene or Curdie for *Princess and the Goblins*)\n",
    "\n",
    "As the list of words corresponds to the list of the columns, we can use `pandas`' column filter to save a copy of our dataframes.\n",
    "\n",
    "First, let's recalculate the document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "docfs = raw_df.apply( lambda x: x[x != 0].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06592851370830824"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs['listen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aaa       2\n",
       "aaarh     1\n",
       "aah       1\n",
       "aall      1\n",
       "aamash    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only the words that have:\n",
    "* document frequency > 1\n",
    "* document frequency / tot doc < 0.9 (i.e. they are attested in less than 90% of the documents); this means in at most 63 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = docfs[(docfs > 1) & (docfs <= 63)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 43,936, we keep only..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25706"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the dataframe `pruned_raw` and `pruned_idf` to hold the filtered versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 25706)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_raw = raw_df[keep]\n",
    "pruned_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abase</th>\n",
       "      <th>abasement</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zu</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zululand</th>\n",
       "      <th>zulus</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æsthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amulet.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brass.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa  ab  aback  abaft  abandon  abandoned  abandoning  \\\n",
       "alice.txt     0   0      0      0        0          0           0   \n",
       "alone.txt     0   0      0      0        0          0           0   \n",
       "amulet.txt    0   0      0      0        0          0           0   \n",
       "beauty.txt    0   0      0      0        0          0           0   \n",
       "brass.txt     0   0      0      0        3          1           0   \n",
       "\n",
       "            abandonment  abase  abasement  ...  zone  zones  zoo  zoological  \\\n",
       "alice.txt             0      0          0  ...     0      0    0           0   \n",
       "alone.txt             0      0          0  ...     0      0    0           0   \n",
       "amulet.txt            0      0          0  ...     0      0    6           1   \n",
       "beauty.txt            0      0          0  ...     0      0    0           0   \n",
       "brass.txt             0      0          0  ...     0      0    0           0   \n",
       "\n",
       "            zu  zulu  zululand  zulus  æneas  æsthetic  \n",
       "alice.txt    0     0         0      0      0         0  \n",
       "alone.txt    0     0         0      0      0         0  \n",
       "amulet.txt   0     0         0      0      0         0  \n",
       "beauty.txt   0     0         0      0      0         0  \n",
       "brass.txt    0     0         0      0      0         0  \n",
       "\n",
       "[5 rows x 25706 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 25706)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_idf = idf_df[keep]\n",
    "pruned_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "captain     234\n",
       "silver      222\n",
       "doctor      172\n",
       "ship        116\n",
       "sea         110\n",
       "squire      106\n",
       "sir         102\n",
       "jim          97\n",
       "john         84\n",
       "island       81\n",
       "mr           64\n",
       "cap          61\n",
       "treasure     59\n",
       "flint        58\n",
       "rum          57\n",
       "hawkins      52\n",
       "ben          50\n",
       "dr           46\n",
       "already      45\n",
       "cut          45\n",
       "Name: treasure.txt, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_from_df(pruned_raw, 'treasure.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances using `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "princess_text = Text(corpus.words('princess.txt'))\n",
    "treasure_text = Text(corpus.words('treasure.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 19 of 19 matches:\n",
      "n ' t like it .\" \" Who don ' t like it ?\" \" The cobs , as we call them .\" \" Don ' t !\" said the nurs\n",
      "r lack of time to wind it up as he \" dodged the cobs ,\" would be in what seemed the most hopeless en\n",
      "e goblin miners were about . CHAPTER XIII . THE COBS ' CREATURES ABOUT this time , the gentlemen who\n",
      "wing mass , which he knew must be a knot of the cobs ' creatures . Before he could recover his feet \n",
      "nd still stood thinking . It was clear that the cobs ' creatures had found his axe , had between the\n",
      "nly surrounded by about half - a - dozen of the cobs , the first I had ever seen , although I had he\n",
      " or another moon or anything of that sort . The cobs dropped persecuting me , and looked dazed , and\n",
      "a white pigeon . But whatever it was , when the cobs caught sight of it coming straight down upon th\n",
      "it no more . But I had no more trouble with the cobs that night , or at any time afterward .\" \" How \n",
      " I have nearly discovered in what direction the cobs are mining . If I am right , I know something e\n",
      " angle of every turning I take until I find the cobs at work , and so get a good idea in what direct\n",
      "ything about it . They would spoil it all . The cobs would only try some other plan -- they are such\n",
      "denly he heard a great thundering sound . \" The cobs are coming !\" he said . \" They didn ' t believe\n",
      " They didn ' t believe a word I told them ! The cobs ' ll be carrying off the princess from under th\n",
      "eous bellowing , which sounded victorious . The cobs were in the house ! He sprang from his bed , hu\n",
      "r . I ' m so glad you ' re come ! I thought the cobs must have got you again !\" With a heart full of\n",
      "mouth to kiss her . \" Then you didn ' t see the cobs ?\" asked Curdie . \" No ; I haven ' t been into \n",
      "the mountain , I told you , Curdie .\" \" But the cobs have been into your house -- all over it -- and\n",
      "ght of it since I got up to go down amongst the cobs !\" \" Let me see the wound ,\" said his mother . \n"
     ]
    }
   ],
   "source": [
    "princess_text.concordance('cobs', width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 39 matches:\n",
      "the ship we could see nothing of the house or stockade , for they were quite buried among trees ; an\n",
      "lutter in the air above a wood . PART 4 . The Stockade CHAPTER 16 . Narrative Continued by the Docto\n",
      " pulled straight in , in the direction of the stockade upon the chart . The two who were left guardi\n",
      "d not gone a hundred yards when I reached the stockade . This was how it was : a spring of clear wat\n",
      "r out of the ship , but not yet ashore in our stockade . CHAPTER 17 . Narrative Continued by the Doc\n",
      "any moment . \" I cannot keep her head for the stockade , sir ,\" said I to the captain . I was steeri\n",
      "not only the danger of being cut off from the stockade in our half - crippled state but the fear bef\n",
      "he strip of wood that now divided us from the stockade , and at every step we took the voices of the\n",
      "r we came to the edge of the wood and saw the stockade in front of us . We struck the enclosure abou\n",
      " get the poor old gamekeeper hoisted over the stockade and carried , groaning and bleeding , into th\n",
      "as better , and the ball descended inside the stockade , scattering a cloud of sand but doing no fur\n",
      " forward . Well armed , they stole out of the stockade , but it proved a useless mission . The mutin\n",
      "ins , safe and sound , come climbing over the stockade . CHAPTER 19 . Narrative Resumed by Jim Hawki\n",
      " Resumed by Jim Hawkins : The Garrison in the Stockade AS soon as Ben Gunn saw the colours he came t\n",
      "t of it ; and here they are ashore in the old stockade , as was made years and years ago by Flint . \n",
      "l I durst not venture in the direction of the stockade , where the balls fell oftenest , I had begun\n",
      "ing something with axes on the beach near the stockade -- the poor jolly - boat , I afterwards disco\n",
      "t length I thought I might return towards the stockade . I was pretty far down on the low , sandy sp\n",
      "egained the rear , or shoreward side , of the stockade , and was soon warmly welcomed by the faithfu\n",
      "slopes of the knoll and all the inside of the stockade had been cleared of timber to build the house\n",
      " green among the sand . Very close around the stockade -- too close for defence , they said -- the w\n",
      " enough , there were two men just outside the stockade , one of them waving a white cloth , the othe\n",
      "t , to let me safe and sound out of this here stockade , and one minute to get out o ' shot before a\n",
      "arm had been absurd . Then he advanced to the stockade , threw over his crutch , got a leg up , and \n",
      "loughed down the sand , was helped across the stockade , after four or five failures , by the man wi\n"
     ]
    }
   ],
   "source": [
    "treasure_text.concordance('stockade', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Tf-Idf normalization with the `TfIdfVectorizer` from `scikit-learn` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TfIdfVectorizer` from Python's library for data analysis `scikit-learn` implements a different calculation of the metric than the one discussed by Jurafksy and Martin. Most notably, it doesn't scale the term frequencies with the log10. Eventually, this gives higher relevance to more frequent words.\n",
    "\n",
    "See:\n",
    "* the official [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for the `TfIdfVectorizer`\n",
    "* this [discussion](https://programminghistorian.org/en/lessons/analyzing-documents-with-tfidf) in the popular (and very useful) blog *The Programming Historian*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=.9, \n",
    "                             min_df=2, stop_words=None, use_idf=True, norm=None)\n",
    "dt_matrix_idf = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "dense = dt_matrix_idf.todense()\n",
    "denselist = dense.tolist()\n",
    "dt_df = pd.DataFrame(denselist, columns=feature_names, index=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abaft</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abase</th>\n",
       "      <th>abasement</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zu</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zululand</th>\n",
       "      <th>zulus</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æsthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alice.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amulet.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.90944</td>\n",
       "      <td>2.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beauty.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brass.txt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.696431</td>\n",
       "      <td>1.980829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25706 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aaa   ab  aback  abaft   abandon  abandoned  abandoning  \\\n",
       "alice.txt   0.0  0.0    0.0    0.0  0.000000   0.000000         0.0   \n",
       "alone.txt   0.0  0.0    0.0    0.0  0.000000   0.000000         0.0   \n",
       "amulet.txt  0.0  0.0    0.0    0.0  0.000000   0.000000         0.0   \n",
       "beauty.txt  0.0  0.0    0.0    0.0  0.000000   0.000000         0.0   \n",
       "brass.txt   0.0  0.0    0.0    0.0  6.696431   1.980829         0.0   \n",
       "\n",
       "            abandonment  abase  abasement  ...  zone  zones       zoo  \\\n",
       "alice.txt           0.0    0.0        0.0  ...   0.0    0.0   0.00000   \n",
       "alone.txt           0.0    0.0        0.0  ...   0.0    0.0   0.00000   \n",
       "amulet.txt          0.0    0.0        0.0  ...   0.0    0.0  20.90944   \n",
       "beauty.txt          0.0    0.0        0.0  ...   0.0    0.0   0.00000   \n",
       "brass.txt           0.0    0.0        0.0  ...   0.0    0.0   0.00000   \n",
       "\n",
       "            zoological   zu  zulu  zululand  zulus  æneas  æsthetic  \n",
       "alice.txt     0.000000  0.0   0.0       0.0    0.0    0.0       0.0  \n",
       "alone.txt     0.000000  0.0   0.0       0.0    0.0    0.0       0.0  \n",
       "amulet.txt    2.791759  0.0   0.0       0.0    0.0    0.0       0.0  \n",
       "beauty.txt    0.000000  0.0   0.0       0.0    0.0    0.0       0.0  \n",
       "brass.txt     0.000000  0.0   0.0       0.0    0.0    0.0       0.0  \n",
       "\n",
       "[5 rows x 25706 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "captain      328.878835\n",
       "jim          298.705830\n",
       "silver       266.206566\n",
       "doctor       256.705955\n",
       "squire       236.607230\n",
       "hawkins      217.258799\n",
       "ship         165.476148\n",
       "rum          146.411107\n",
       "john         137.682717\n",
       "ben          135.585838\n",
       "stockade     129.899483\n",
       "sea          124.688453\n",
       "flint        124.187970\n",
       "island       120.890595\n",
       "sir          117.252237\n",
       "morgan       116.711153\n",
       "anchorage    101.062293\n",
       "mutineers     96.095238\n",
       "aboard        94.910087\n",
       "dr            94.658354\n",
       "Name: treasure.txt, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_df.loc['treasure.txt'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Digital Tools 4 Humanities",
   "language": "python",
   "name": "digitools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
